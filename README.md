# genai-chat-local-tabular-data
Project to use Open Source LLM to chat securely with your local tabular data without any cost!

To start using:
- Download ollama from https://ollama.com/download
- Pull Open Source model `codellama` by running following commands from Terminal.
    `ollama pull codellama`
- Clone the git repo and install all python dependencies using:
    `pip install -r requirements.txt`
- Run the application using:
    `python app.py`

Application will be hosted securely on your local at:
http://127.0.0.1:7860

The application doesn't need any internet connection, any API Keys to run. So effectively IT IS FREE to RUN!!!

